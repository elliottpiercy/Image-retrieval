{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Content-Based High-Resolution Remote Sensing Image Retrieval via Unsupervised Feature Learning and Collaborative Affinity Metric Fusion.\n",
    "\n",
    "Unsupervised Metric Fusion by Cross Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 feature CAMF. Easily extended to n features.\n",
    "class collaborative_affinity_metric_fusion():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Creates global affinity matrix by computing the euclidean distance between image feature vectors and applying non-linearity\n",
    "    # Equation 3\n",
    "    def affinity_matrix(self, features):\n",
    "        W = np.array([])\n",
    "        control_constant = self.get_median(features)\n",
    "\n",
    "\n",
    "        from sklearn.metrics.pairwise import euclidean_distances\n",
    "        for feature_a in features:\n",
    "            for feature_b in features:\n",
    "\n",
    "                euclidean_dist = euclidean_distances(np.atleast_2d(feature_a),np.atleast_2d(feature_b))\n",
    "                W = np.append(W,np.exp(euclidean_dist / control_constant))\n",
    "\n",
    "        return np.reshape(W,(len(features),len(features)))\n",
    "\n",
    "\n",
    "\n",
    "    # Calculates the median of the distances between feature vectors. Used as a control constant.\n",
    "    def get_median(self, features):\n",
    "        distances = np.array([])\n",
    "        from sklearn.metrics.pairwise import euclidean_distances\n",
    "        for i in features:\n",
    "            for j in features:\n",
    "                distances = np.append(distances,euclidean_distances(np.atleast_2d(i),np.atleast_2d(j)))\n",
    "\n",
    "        return np.median(distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Creates a local affinity matrix. If the neighbouring nodes are a minimal neighbour then keep the value. Else = 0.\n",
    "    # Equation 5.\n",
    "    def local_affinity_matrix(self, W, neighbours):\n",
    "        # Iterate over rows\n",
    "        for row in range(len(W)):\n",
    "            # Find closest N neighbours\n",
    "            min_list = np.argsort(W[row])[:neighbours]\n",
    "            # Find set difference and set larger neighbours to 0\n",
    "            invalid_neighbours = list(set(np.arange(len(W[row])))-(set(min_list)))\n",
    "            W[row][invalid_neighbours] = 0\n",
    "        return W\n",
    "\n",
    "    \n",
    "\n",
    "    # Normalise W along each row. \n",
    "    def normalise(self, data):\n",
    "        for row in range(len(data)):\n",
    "            data[row] = data[row] / np.sum(data[row])\n",
    "        return np.reshape(data,(1,data.shape[0],data.shape[1]))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Normalise W to give us the status matrix. Global graph. Equation 4.\n",
    "    def status_matrix_creation(self, W):\n",
    "        return self.normalise(W)\n",
    "\n",
    "\n",
    "    # Normalise W_ to give us the status matrix. Local graph. Equation 6.\n",
    "    def kernel_matrix_creation(self, W_):\n",
    "        return self.normalise(W_)\n",
    "\n",
    "\n",
    "\n",
    "    # Creates the status and kernel matrices based on the extracted features and the number of local neighbours\n",
    "    def create_graphs(self, features, neighbours):\n",
    "        status_matrix = np.zeros((1,len(features),len(features)))\n",
    "        kernel_matrix = np.zeros((1,len(features),len(features)))\n",
    "\n",
    "\n",
    "        W = self.affinity_matrix(features)\n",
    "        s_matrix = self.status_matrix_creation(W)\n",
    "        status_matrix = np.concatenate((status_matrix,s_matrix),axis=0)\n",
    "\n",
    "        from copy import deepcopy\n",
    "        W_ = self.local_affinity_matrix(deepcopy(W),neighbours)\n",
    "        k_matrix = self.kernel_matrix_creation(W_)\n",
    "        kernel_matrix = np.concatenate((kernel_matrix,k_matrix),axis=0)\n",
    "\n",
    "        return np.delete(status_matrix,0,axis=0), np.delete(kernel_matrix,0,axis=0)\n",
    "    \n",
    "    # Find the diffusion indexs due to the fact k!=m. Randomly shuffle until k!=m.\n",
    "    def status_diffusion_index(self, graphs):\n",
    "        M = np.arange(graphs)\n",
    "        np.random.shuffle(M)\n",
    "\n",
    "        while True:\n",
    "            if (M != np.arange(graphs)).all():\n",
    "                break\n",
    "            else:\n",
    "                np.random.shuffle(M)\n",
    "        return M\n",
    "    \n",
    "\n",
    "    # Applys cross diffusion to the status matrices and kernel matrices. This merges the features gathered from multiple \n",
    "    # algorithms into one matrix that can be queried for image similarity. Equation 7.\n",
    "    def cross_diffusion(self, status_matrix, kernel_matrix):\n",
    "        T = 20\n",
    "        eta = 1\n",
    "        k = self.status_diffusion_index(status_matrix.shape[0])\n",
    "        M = status_matrix.shape[0]\n",
    "        \n",
    "        # Iterate over feature graphs\n",
    "        for graph in range(len(k)):\n",
    "            for t in range(T):\n",
    "                # Application of equation 7.\n",
    "                status_matrix[graph] = kernel_matrix[graph] * ((1/M-1) * np.sum(status_matrix[k[graph]])) * kernel_matrix[graph].T + eta * np.identity(kernel_matrix.shape[1])\n",
    "\n",
    "        return np.mean(status_matrix,axis=0)\n",
    "\n",
    "\n",
    "    # Merges graphs into ones array to be used in the cross diffusion step.\n",
    "    def merge_graph(self, graph_1, graph_2):\n",
    "        return np.concatenate((graph_1, graph_2), axis=0)\n",
    "    \n",
    "    \n",
    "    # Find the n closest images using W_FAM matrix.\n",
    "    def image_similarity(self, W_FAM, neighbours):\n",
    "        image_locations = np.array([])\n",
    "        \n",
    "        for row in W_FAM:\n",
    "            # Locate min n neighbours ignoring the 1st position due to self similarity.\n",
    "            min_distance = np.argsort(row)[::-1][1 :neighbours+1]\n",
    "            image_locations = np.append(image_locations, min_distance)\n",
    "        \n",
    "        return np.reshape(image_locations,(W_FAM.shape[0],neighbours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_algo_1 = np.random.rand(51,1024)\n",
    "features_algo_2 = np.random.rand(51,1024)\n",
    "\n",
    "\n",
    "CAMF = collaborative_affinity_metric_fusion()\n",
    "\n",
    "status_matrix_1, kernel_matrix_1 = CAMF.create_graphs(features_algo_1, neighbours = 20)\n",
    "status_matrix_2, kernel_matrix_2 = CAMF.create_graphs(features_algo_2, neighbours = 20)\n",
    "\n",
    "\n",
    "status_matrix = CAMF.merge_graph(status_matrix_1, status_matrix_2)\n",
    "kernel_matrix = CAMF.merge_graph(kernel_matrix_1, kernel_matrix_2)\n",
    "W_FAM = CAMF.cross_diffusion(status_matrix, kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 21. 32. 33. 22. 45. 39. 44.  6. 31.]\n",
      " [ 1. 25. 33.  6. 23. 24. 27. 36.  8. 26.]\n",
      " [ 2. 50. 35. 26. 16. 40. 23. 21. 18. 46.]\n",
      " [ 3. 42. 39. 40. 21. 35. 45. 24. 31. 37.]\n",
      " [ 4. 26. 46. 19. 21. 39. 47. 45. 50. 14.]\n",
      " [ 5.  8. 28. 16. 13. 12. 32. 47. 38. 21.]\n",
      " [ 6.  1. 33. 31. 22.  0. 13.  8.  5.  7.]\n",
      " [ 7. 18. 23. 17. 14. 33. 11. 12. 25. 31.]\n",
      " [ 8. 50. 31.  9. 38. 24.  5.  1. 21. 12.]\n",
      " [ 9. 24.  8. 25. 12. 37. 50. 38. 46. 43.]\n",
      " [10. 17. 36. 15. 34.  8. 50. 26. 49. 24.]\n",
      " [11. 36. 28. 20. 24. 21. 15.  7. 14. 50.]\n",
      " [12. 38. 50. 24. 28.  9. 32. 25. 13. 27.]\n",
      " [13. 39. 49. 41. 34. 12.  5.  6. 33.  2.]\n",
      " [14. 22. 39. 38.  7.  9. 25. 11.  1. 16.]\n",
      " [15. 10. 11. 19. 50. 16. 26. 24. 22. 21.]\n",
      " [16. 35. 36. 27. 26. 45. 31.  2. 24. 38.]\n",
      " [17. 42.  7. 44. 10. 18. 35. 29. 27.  8.]\n",
      " [18.  7. 46. 17. 43. 32. 38. 36.  2. 39.]\n",
      " [19. 50. 34.  4. 21.  0. 45. 15. 43. 25.]\n",
      " [20. 11. 16. 12. 23. 22. 19. 18. 17. 15.]\n",
      " [21.  0. 22.  3. 30.  4.  8. 19. 11. 36.]\n",
      " [22. 14. 39. 38. 21. 34.  0. 37.  6. 47.]\n",
      " [23.  7.  1. 48. 36. 12.  2. 31. 49. 35.]\n",
      " [24. 32.  9. 44. 12.  1. 11.  8. 16. 48.]\n",
      " [25.  1. 46. 27.  9. 12. 49. 50. 14. 32.]\n",
      " [26. 16.  4.  2. 30. 47.  1. 12. 50. 24.]\n",
      " [27. 32. 16. 48. 25.  1. 12. 30. 33. 45.]\n",
      " [28. 11. 12. 45.  5. 24. 31. 27. 48.  7.]\n",
      " [29. 45. 17. 34. 32. 50. 15. 23. 22. 19.]\n",
      " [30. 37. 26. 33. 21. 27. 34.  1.  8. 49.]\n",
      " [31.  8. 16.  6. 48. 28. 23. 43.  0. 38.]\n",
      " [32. 24. 27.  0. 12. 18. 50.  5. 45. 33.]\n",
      " [33.  1.  0. 49.  6. 30. 41.  7. 27. 37.]\n",
      " [34. 35. 38. 13. 22. 19. 30. 41. 10.  5.]\n",
      " [35. 16. 34.  2. 42. 41.  3. 17. 23. 36.]\n",
      " [36. 11. 16. 37. 23. 10.  1. 18. 21. 50.]\n",
      " [37. 48. 36. 30. 43.  9. 22. 33.  1.  3.]\n",
      " [38. 12. 48. 34. 22.  8. 14. 47. 16. 43.]\n",
      " [39. 13.  3. 42. 22. 14. 49.  0.  4. 12.]\n",
      " [40.  3. 45.  2. 46. 50. 15. 23. 22. 20.]\n",
      " [41. 13. 35. 33. 12. 43. 34. 15. 49. 24.]\n",
      " [42. 17.  3. 39. 35. 50. 16. 49. 24. 23.]\n",
      " [43. 18. 37. 38.  9. 41. 31. 49. 33. 19.]\n",
      " [44. 17. 24. 46.  0. 12. 27.  3.  9. 10.]\n",
      " [45. 16. 40. 48. 28.  0.  3. 29. 27. 32.]\n",
      " [46. 25. 18. 44. 40.  4.  9. 39.  2.  0.]\n",
      " [47. 38. 26.  5. 22.  4. 49. 24. 23. 20.]\n",
      " [48. 37. 38. 27. 23. 45. 31. 24.  9. 28.]\n",
      " [49. 13. 39. 33. 25. 43. 23. 30. 19. 24.]\n",
      " [50.  2. 12.  8. 19.  9. 25. 32. 36. 40.]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = CAMF.image_similarity(W_FAM,10)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
